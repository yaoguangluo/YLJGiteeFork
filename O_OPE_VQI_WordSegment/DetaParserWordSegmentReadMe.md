# 函数名
DNA元基催化:德塔极速分词包

## 使用须知

## 主题一-> 词意
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> คลังข้อความภาษาไทยขนาดใหญ่สำหรับการปรับรุ่นเสร็จสมบูรณ์。
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> Cơ sở dữ liệu tiếng việt chuẩn hoàn thành, không tối ưu hóa phiên bản。
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> Rumah corpus indonesia selesai. Versi tak dioptimalkan。
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> Die deutsche sprachdatenbank wurde nicht geändert.
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> أُنجزت نسخة غير معدلة من قاعدة المفردات المتخصصة باللغة العربية 
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> Versión no detectada del corpus español completa。
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> 한국의 언어 자재 고는 이미 완벽하다。
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> 日本语のデータベースはすでに第1版が完成しました。
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> Le corpus français est terminé  A1, A2, A3, A4, B1, B2。 
###### 1 : The first unrevised version has been completed: 12 professional level corpora of Chinese, Chinese pinyin, French, German, Korean, Japanese, Spanish, Russian, indonesia , Arabic, Vietnam and Thailand languages.
###### 2 -> 第1版未修正版:中国、フランス、ドイツ、韩国、日本、スペイン、ロシア、アラビア语8种类の専门レベルの言语データベースが完成した。
###### 3 -> 이미 제1 판의 수정되지 않은 수정판은 중국, 프랑스, 독일, 한국, 일본, 서부, 로씨야, 아랍어 등 8개 전업급 언어자료창고이다.
###### 4 -> La première édition n’a pas été modifiée: le corpus des langues chinoise, française, allemande, coréenne, japonaise, occidentale, russe et arabe.
###### 5 -> Die erste unänderte fassung der ersten ausgabe wurde abgeschlossen: in der mitte, frankreich, korea, japan, russland, dem 8. Sprachzentrum auf hoher ebene
###### 6 -> Завершено первое неисправленное издание: Китай, Франция, Германия, хан, Япония, западная, российская и арабская языки, восемь специализированных корпусов.
###### 7 -> Se han completado las primeras ediciones sin modificaciones: el corpus juris de 8 niveles profesionales en idiomas chino, francés, alemán, coreano, japonés, occidental, ruso y árabe.
###### 8 -> وقد اكتملت الطبعة الأولى من دون تعديل، وهي مجموعة من ثماني مجموعات متخصصة من اللغات الإسبانية والفرنسية والألمانية والورية واليابانية والغربية والروسية.
###### 9 -> Rumah corpus indonesia selesai. Versi tak dioptimalkan。
###### 10 -> Cơ sở dữ liệu tiếng việt chuẩn hoàn thành, không tối ưu hóa phiên bản。
###### 11 -> คลังข้อความภาษาไทยขนาดใหญ่สำหรับการปรับรุ่นเสร็จสมบูรณ์。

##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能-> 首次采用《VPC架构》海量线程注册保证调用函数速度。 功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  支持海量并发运算，后端接口调用运算，纯全虚接口同步运算。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  经过SONAR 最高级认证（感知最高认证，语义最高认证，语法最高认证，行为最高认证，逻辑最高认证）。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  扩展词语非常简单->基于 《格式化线性语料库》。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  查询词语非常方便->基于 《离散森林网络加权字典递归索引》。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  搜索词语非常迅捷->基于 《2分法搜索 欧基里德距离 进行 位运算散列存储 字符集数据森林》。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  匹配词语非常精准->基于 《决策树深度 NLP 正向隐马可夫匹配》。功能作者-> 罗瑶光      
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  词频统计接近光速->基于《线性科学最强的快排第6代的基础上作者进行以作者名字命名的小高峰过滤法修正算法，导致快排6的速度再翻2倍》。 (词频统计非线性排序算法已经更新了罗瑶光小高峰过滤快排三代. 2019-04-23)       
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  速度->每秒高达2200万(201904012)中文简体字准确分词。 因为通过国际SONAR最高认证，牺牲了程序执行时间十分之三的速度效率（自行修改去掉sonar认知模式可达3000万字分词每秒，性能比应该是世界第二，世界第一赠给高斯林先生，因为我用的是java，没办法）。 测试环境（win7， 64位， 16g ram，intel i5-7500） 20181208 功能作者-> 罗瑶光          
https://github.com/yaoguangluo/Deta_Parser/tree/master/wordSegment/org/tinos/test        
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  中英混合分词。最高达到每秒2200万 ~ 2700万中英文混合常规格式分词。（每毫秒分22,000字+）20190412 功能作者->罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  速度每秒高达900万词语的中文词性索引。（Part Of Speech, POS），功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  机制为分词和词性分析可拆分使用。采用一次实例，多并发执行思想。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  词库->多达26300+的中文语料库精确简体中文词汇，有效的辨别新词。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  大小->55Kb。
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  多核模式->可以自己写 parallelStream() 函数去实现，jdk8以上已经支持, CogsBinaryForestAnalyzer 支持海量多核多线程并发安全 。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  安全->VPC架构采用纯虚函数做反向映射跳过IOC，效率增加，线程安全高度严格保障。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  部分中文短句翻译英语。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  中英混合分词。最高达到每秒2200万 ~ 3000万中英文混合常规格式分词。功能作者-> 罗瑶光        
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  病句中乱码分析。功能作者-> 罗瑶光        
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  VPC进化到VPCS, 静态分流加速每秒又多增100万分词。功能作者-> 罗瑶光      
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  12国语言翻译词汇录入系统。 Mr.Yaoguang.Luo 20190310 功能作者-> 罗瑶光      
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  第一次语料库森林进行序列化优化已完成（分词速度提高1.5%），导致ICA内核生成速度翻倍。20190320 功能作者 罗瑶光。     
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  逐步完善歧义,复杂,病句,变态,狂虐,句型的分词.感谢测试用例病句提供者如下:       
https://github.com/yaoguangluo/Deta_Parser/blob/master/wordSegment/org/tinos/test/DemoPOS.java      
(https://blog.csdn.net/dreamz*************ls/88108568      
https://my.oschina.*************135746) 道德清洗中. 对曾经提供负面的歧义病句的单位表示感谢 同时表示道歉,这里 链接过滤了.         


## 主题二-> 词感
##### ![实例](http://progressed.io/bar/100) 德塔意识图灵机项目已经启动。 20190313 功能作者-> 罗瑶光       
##### ![实例](http://progressed.io/bar/100) ICA 内核训练集生成算法优化。20190317 功能作者-> 罗瑶光    
##### ![实例](http://progressed.io/bar/100) 基于贝叶斯统计RNN函数集，通过频率排序进行函数校准，并进行动词的特殊用法修正。20190319 功能作者 罗瑶光      
##### ![实例](http://progressed.io/bar/100) 一种罗氏教育评估图灵机1.0如下->基于ANN的训练形谓词比的核心率进行贝叶斯结果分析。20190323 功能作者 罗瑶光          
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->  病句分析非常完善->基于 《双向马可夫词性 POS 打分修正策略》。功能作者-> 罗瑶光         
##### ![实例](http://progressed.io/bar/100?title=completed)已完成功能->情感语料库第一版本未修正版本。 Mr.Yaoguang.Luo      
注意1->该正面，褒义，负面，贬义，中性情感语料库有一定比重的表达作者的主观判断，比如思维误差，肯定环境，否定环境，哲学精神论等，如果引起不适，请慎重使用和借鉴修改。如果该情感库对第三方导致任何工程问题，作者不做任何解释和负法律责任。       
注意2: 因为关键字和形谓词模型的应用不确定性，意识和社会形态的溯源问题以及字典理解的误差率，该情感语料库不做任何解释在基于法律与道德的临界线区分应用上。          
注意3: 多语意识场合，该情态库不做任何情形分类评估标准，也不做引导性评估。        
##### ![实例](http://progressed.io/bar/100) 基于 HMM matrix 进行 Nomarlization 然后做 未优化的 ANN 简单 训练版本 map reduce 测试。功能作者-> 罗瑶光      
https://github.com/yaoguangluo/Deta_Parser/blob/master/sensingMap/org/tinos/sensing/test/ANNTest.java     

## 主题三-> 词境
##### ![实例](http://progressed.io/bar/100) 基于环境，场合，动机，目的，倾向和预判评估进行自然语言第6感意识分析。 功能作者-> 罗瑶光
https://github.com/yaoguangluo/Deta_Parser/blob/master/emotionMap/org/tinos/emotion/test/EnvironmentTest.java     
##### ![实例](http://progressed.io/bar/100) Emotion Ratio Matrix for ANN ICA 6.th sensing test 功能作者-> 罗瑶光
https://github.com/yaoguangluo/Deta_Parser/blob/master/sensingMap/org/tinos/sensing/test/SensingTest.java
##### ![实例](http://progressed.io/bar/100) 正在做功能->语言心理学读心术。功能作者-> 罗瑶光
##### ![实例](http://progressed.io/bar/92) 正在做功能->动机判断的情态语料库。已经附带可运行实例地址如下。功能作者-> 罗瑶光
https://github.com/yaoguangluo/Deta_Parser/blob/master/emotionMap/org/tinos/emotion/test/EmotionTest.java
##### ![实例](http://progressed.io/bar/100) 基于ICA做马可夫行为集合，通过误差容错率进行词性校准，找出副词特殊用法陷阱，并进行了修正。
https://github.com/yaoguangluo/Deta_Parser/blob/master/wordSegment/org/tinos/engine/pos/imp/POSControllerImp.java 20190318 功能作者 罗瑶光
##### ![实例](http://progressed.io/bar/100) 一种用于行为评估的罗氏多文本量子观测角度自适应行为ICA增量训练内核已经初步定义，之后开始做ICA + CNN内核计算.20190316
##### ![实例](http://progressed.io/bar/100) 情感集图灵算子进行认知化。下一步进行带训练集意识加工处理为ICA做预处理。 20190315功能作者-> 罗瑶光      

## 主题四-> 词灵
##### ![实例](http://progressed.io/bar/100)      
一种基于 ANN{Summing, Emotion, Motivation, Environment} * RNN{Covex, Euclid, POS} = DNN{LWA，Entropy}         
罗氏读心术已经更新并进行了图灵算子优化。 20190314 功能作者-> 罗瑶光        
![实例](https://github.com/yaoguangluo/Nero_Parser/blob/master/deta_mind_reading.png)         
###### https://github.com/yaoguangluo/Deta_Parser/blob/master/sensingMap/org/tinos/sensing/test/DNNTest.java         
###### http://tinos.qicp.vip/data.html (德塔ANN 维度功能)    
###### http://tinos.qicp.vip/data.html (德塔RNN 向量功能)     
###### http://tinos.qicp.vip/data.html (德塔DNN 读心功能)      
##### ![实例](http://progressed.io/bar/40) 接受教育能力行为训练工程已经启动。 20190321 功能作者 罗瑶光。 目标预计每秒分析700万字文章。        
https://github.com/yaoguangluo/Deta_Parser/blob/master/behaviorMap/org/tinos/behavior/test/EducationLevelTest.java       
##### ![实例](http://progressed.io/bar/60) 12国语言混合快分作文辅导功能.目前支持中, 英, 繁, 简, 日, 韩 作文辅导和评阅功能.        
http://tinos.qicp.vip/data.html (作文辅导功能)       
##### ![实例](http://progressed.io/bar/100) 一种简洁快速的文章文学周期性价比率研究。20190322 功能作者 罗瑶光。       
https://github.com/yaoguangluo/Deta_Parser/blob/master/behaviorMap/org/tinos/behavior/test/LiterarinessLevelTest.java        
##### ![实例](http://progressed.io/bar/20) 资本运作，消费评估，购买力分析的商业体系已经启动。 20190324 功能作者 罗瑶光。       
商业开发将在官方网站展示->http://tinos.qicp.vip/              
##### ![实例](http://progressed.io/bar/1) Deta 中译英图灵项目已经启动.(谷歌,有道,百度等在语言句子翻译项目 非常成功, 德塔不会将研究重心花在全文翻译领域. 中译英图灵项目主要用在多语意识分析子项目.)          
https://github.com/yaoguangluo/Deta_Parser/blob/master/neroMap/org/tinos/test/DemoTSLT.java      








#### 引用
中华人民共和国 国家版权局 软著登字第3951366号 德塔自然语言图灵系统 V10.6.1  
CNN思想 提出者 Yann LeCun，Wei Zhang，Alexander Waibel 等   
ANN思想 数据挖掘教材   
RNN思想 提出者 M. I. Jordan，Jeffrey Elman   
HMM思想 提出者 隐.马尔可夫        
增加注释下: 我的6万中英文语义词库因为 有涉及 新华字典的词语录入. 没有在 德塔自然语言图灵系统 V10.6.1 个人软著的申请资源中.   
1 用复旦大学的免费分词软件(LGPL-3.0 license)进行将词语的词性标注.       
2 用百度,谷歌,有道,免费在线翻译进行词语的翻译, 特别感谢有道, 翻译质量最高.   
3 6万词库有2万是 百度上买了新华字典电子书录词语, 感谢新华字典. (仅仅录了2万个词语的名而已. 词语解释, 词语造句, 偏旁部首, 同义反义词汇等全部没有抄录.
我当时用浏览器中 英文单词对应的中文翻译记录的同义词汇)  
4 另外4万是我在新华字典的分词后 出现的未知词汇不断的记录统计下, 然后增加的.   
4.1 Github竟然还是卡阿卡的, 我就再细节溯源.我在百度文库上不单买了新华字典的词语, 我还买了成语词汇列表和国家中文语言过级的词汇(不多,几百几千个而已),我都只录了词语而已.
4.1.1 再说一个细节, 记得当时我买了有一个词汇txt竟然是一行显示,我还因此把算法按行读改成了按字节buffer读. 可以查嘛.
4.2 我的购买方式是微信类扫码百度文库包月能免费下载买的.(我的支付宝虽然一年多没用了, 现在一直没有注销.国家可查询)
5 一部份词语是未知的单字进行同词性连着进行合并出来的新词并记录的.    
    
###### 申明
GNU GPL 2.0 协议 100% 源码全部开源发布, 避嫌.
申明下
1 我的分词方法函数在2019年4月3号就写完了, 2019年5月28号就下证了.
2 复旦大学的邹锡鹏 在同年7月才提出新的分词方法.(刚浏览器搜的时候弹出这个信息, 我没细看)
3 我的源码已经全部开源, 双方git都有开源, giff一下, 是否逻辑相同.就是了,新的分词方法和我相同就是 邹锡鹏抄袭.
4 我的源码4月3号的 和 复旦的逻辑相同 就是 罗瑶光抄袭. 简单的很. 注明我的分词当时每秒达到1800万中文分词速度.
当时 lucene 中文分词速度每秒20万.(刚看了下,复旦那篇论文Multi-Criteria Chinese Word Segmentation with Transformer
采用的是机器学习的训练分词, 和本人的 按人类语言语法定义分词 不同)

罗瑶光
20210507